#!/usr/bin/env python3
from glob import glob
import os
import shutil
import re

include: "common.snake"

DBs = ["refseq", "genbank"]
Domains = ["bacteria", "archaea"]

#
# the update strategy of the summaries is the same as in
# download_ncbi_taxonomy.snake
#
# if the summaries are new, an update of the sequences if triggered;
# this only downloads new sequences; it is robust for the case of
# errors / broken downloads
#

def all_targets(wildcards):
  summaries_updated=path.asmsummary/"update_summaries.done"
  if os.path.exists(summaries_updated):
    return [summaries_updated, path.asmsummary/"update_sequences.done"]
  else:
    return [summaries_updated]

rule all:
  input: all_targets
  shell:
    """
    rm {input[0]}
    """

checkpoint update_all_summaries:
  input:
    expand(path.asmsummary/"update_summaries.{db}.{domain}.done",
      db=DBs, domain=Domains)
  output:
    touch(path.asmsummary/"update_summaries.done")

rule prepare_update_summaries:
  params:
    possible_input=str(path.asmsummary/"assembly_summary_{db}_{domain}.txt")
  output:
    current=path.asmsummary/"current_assembly_summary_{db}_{domain}.txt"
  shell:
    """
    if [ -e {params.possible_input} ]; then
      mv {params.possible_input} {output.current}
    else
      touch {output.current}
    fi
    """

rule update_summaries:
  input:
    to_update=path.asmsummary/"current_assembly_summary_{db}_{domain}.txt"
  output:
    done=temp(touch(\
      path.asmsummary/"update_summaries.{db}.{domain}.done")),
    updated=path.asmsummary/"assembly_summary_{db}_{domain}.txt"
  params:
    remote="ftp://ftp.ncbi.nlm.nih.gov/genomes/{db}/{domain}/"+\
           "assembly_summary.txt",
    timestamp=str(path.asmsummary/
        "assembly_summary_{db}_{domain}.update_timestamp")
  shell:
    """
    if [ -e {params.timestamp} ]; then
      curl -o {output.updated} -z {params.timestamp} {params.remote}
    else
      curl -o {output.updated} {params.remote}
    fi
    if [ -e {output.updated} ]; then
      rm {input.to_update}
      touch {params.timestamp}
    else
      mv {input.to_update} {output.updated}
    fi
    """

rule update_all_sequences:
  input:
    expand(path.asmsummary/"update_sequences.refseq.{domain}.done",
           domain=Domains)
  output:
    temp(touch(path.asmsummary/"update_sequences.done"))

rule update_sequences:
  input:
    path.asmsummary/"assembly_summary_refseq_{domain}.update_timestamp",
    path.asmsummary/"complete_genomes_refseq_{domain}.new.done",
    path.asmsummary/"complete_genomes_refseq_{domain}.obsolete.done"
  output:
    temp(touch(path.asmsummary/"update_sequences.refseq.{domain}.done"))

rule list_complete_genomes_for_domain:
  input:
    path.asmsummary/"assembly_summary_{db}_{domain}.txt"
  output:
    path.asmsummary/"complete_genomes_{db}_{domain}.txt"
  run:
    o_f = open(output[0], "w")
    with open(input[0]) as f:
      for line in f:
        if line[0] != "#":
          elems = line.rstrip().split("\t")
          if elems[10] == "latest" and \
             elems[11] == "Complete Genome" and \
             elems[19] != "na":
            # asmacc ftppath
            o_f.write("\t".join([elems[0], elems[19]])+"\n")
    o_f.close()

rule create_updating_plan:
  input:
    path.asmsummary/"complete_genomes_refseq_{domain}.txt"
  output:
    new=temp(path.asmsummary/"complete_genomes_refseq_{domain}.new"),
    obs=temp(path.asmsummary/"complete_genomes_refseq_{domain}.obsolete"),
    rep=report("updating_plan.report_{domain}.tsv")
  params:
    chunkspfx=str(path.genomes/"seq/{domain}/chunk.")
  run:
    filenames=set(os.path.basename(fn) for fn in \
        glob(params.chunkspfx+"*/*_genomic.fna.gz"))
    out_new = open(output.new, "w")
    out_obs = open(output.obs, "w")
    n_new = 0
    n_obs = 0
    with open(input[0]) as f:
      for line in f:
        elems = line.rstrip().split("\t")
        fn = elems[1].split("/")[-1] + "_genomic.fna.gz"
        if fn in filenames:
          filenames.remove(fn)
        else:
          out_new.write(fn+"\t"+elems[1]+"\n")
          n_new += 1
      for fn in filenames:
        out_obs.write(fn+"\n")
        n_obs += 1
    out_new.close()
    out_obs.close()
    with open(output.rep, "w") as f:
      f.write(f"n_new\t{n_new}\n")
      f.write(f"n_obsolete\t{n_obs}\n")

rule move_obsolete_genomes:
  input:
    path.asmsummary/"complete_genomes_refseq_{domain}.obsolete"
  output:
    temp(touch(path.asmsummary/"complete_genomes_refseq_{domain}.obsolete.done"))
  params:
    chunkspfx=str(path.genomes/"seq/{domain}/chunk."),
    obsmaindir=str(path.genomes/"seq/{domain}/obsolete")
  run:
    with open(input[0]) as f:
      for line in f:
        fn = line.rstrip()
        srcfile = glob(params.chunkspfx+"*/"+fn)[0]
        # check if file exists: it may not, if the workflow
        # was previously interrupted by an error
        if os.path.exists(srcfile):
          chunknum = os.path.dirname(srcfile).split("/")[-1].split(".")[1]
          obsdir = params.obsmaindir+("/chunk."+chunknum)
          if not os.path.exists(params.obsmaindir): os.mkdir(params.obsmaindir)
          if not os.path.exists(obsdir): os.mkdir(obsdir)
          shutil.move(srcfile, obsdir)

rule download_new_genomes:
  input:
    path.asmsummary/"complete_genomes_refseq_{domain}.new"
  output:
    temp(touch(path.asmsummary/"complete_genomes_refseq_{domain}.new.done"))
  params:
    downloadtmp=str(path.genomes/"download_in_progress.{domain}"),
    chunkspfx=str(path.genomes/"seq/{domain}/chunk."),
    chunkmaxsize=500
  run:
    shutil.rmtree(params.downloadtmp, ignore_errors=True)
    os.mkdir(params.downloadtmp)
    if os.stat(input[0]).st_size > 0:
      chunknums = \
        [int(os.path.splitext(x)[1][1:]) for x in glob(params.chunkspfx+"*")]
      if len(chunknums) == 0:
        chunknum = 0
        genomenum = 0
      else:
        chunknum = max(chunknums)
        genomenum = \
          len(glob(params.chunkspfx+str(chunknum)+"/*_genomic.fna.gz")) + 1
      chunkdir=params.chunkspfx+str(chunknum)
      if not os.path.exists(chunkdir): os.mkdir(chunkdir)
      with open(input[0]) as f:
        for line in f:
          elems = line.rstrip().split("\t")
          remote_path = elems[1]
          fname = elems[0]
          # check if file exists: it may already, if the workflow
          # was previously interrupted by an error
          found = glob(str(path.genomes/"seq"/wildcards.domain/"**"/fname))
          if found:
            print(f"Skipping {fname} as already dowloaded: {found[0]}")
          else:
            if genomenum == params.chunkmaxsize:
              genomenum = 0
              chunknum += 1
              chunkdir = params.chunkspfx+str(chunknum)
              os.mkdir(chunkdir)
            genomenum+=1
            tmpdest = os.path.join(params.downloadtmp, fname)
            finaldest = os.path.join(chunkdir, fname)
            shell(f"wget {remote_path}/{fname} -O {tmpdest} && "+\
                  f"mv {tmpdest} {finaldest}")
            print(f"Downloaded {fname} as: {finaldest}")
    shutil.rmtree(params.downloadtmp, ignore_errors=True)

rule check_downloaded_files:
  params:
    files=str(path.genomes/"seq"/"*"/"chunk.*"/"*.fna.gz")
  shell:
    """
    for file in {params.files}; do
      if ! gzip -v -t $file; then
        rm $file
        echo "removed invalid file: $file"
      fi
    done
    """
